{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center> AI4LR - Final Assignment [100 Points]","metadata":{"id":"xksEYwr8QXgN"}},{"cell_type":"code","source":"# IMPORTANT\nYour_name = \"Pranav Raj H\"\nYour_emailid = \"vinstarpranav@gmail.com\"","metadata":{"id":"2WVqrOVwm8yz","execution":{"iopub.status.busy":"2023-01-27T13:41:40.861396Z","iopub.execute_input":"2023-01-27T13:41:40.861895Z","iopub.status.idle":"2023-01-27T13:41:40.894133Z","shell.execute_reply.started":"2023-01-27T13:41:40.861819Z","shell.execute_reply":"2023-01-27T13:41:40.893288Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{"id":"vgojAScln93D"}},{"cell_type":"markdown","source":"## Dataset\n- Add [this dataset](https://www.kaggle.com/datasets/romainpessia/artificial-lunar-rocky-landscape-dataset) to your Kaggle notebook.\n\n## Instructions for this project\n- Don't forget to turn on GPU for training your model(s).\n- Without changing anything in the notebook if you run it then you will get the val_iou_score of around 0.20.\n- Your goal of this project is to increase this val_iou_score as much as you can.\n- Evaluation of this project will be based on your best acquired val_iou_score seen in the notebook.\n- Your val_iou_score will be the percentage you will receive for this project. \n- If your best val_iou_score is 0.41 then you will score 41/100 points in this project.\n- Try to avoid any errors before submitting your notebook.\n\n## Tips to increase the performance of your model\n- Increase the number of epochs.\n- Increase the number of layers in your model.\n- Using SOTA high performance networks with transfer learning.\n- Using callbacks and carefully observing your model performance.\n- You can use the methods taught to you in this training program or any other methods of your own choice to increase the performance!\n\n## Guidelines on making changes to this notebook\n**1)** Add a descriptive comment to your code for whatever changes you are making in this notebook.\n- For example, if you are adding an extra Conv2D layer, write about all the aspects of the Conv2D layer you are adding.\n- The commnt should be placed at the point where the layer will be added.\n\n**2)** Show model properties before and after the changes were made.\n- For example, if you changed the layers - added, deleted, e.t.c.\n\n**3)** If you use new data preprocessing techniques that are not already part of this notebook, you must explain their inner workings using markdown cells.\n- Without this explanation, your techniques will not be considered for evaluation.\n- Use texts and images to explain this process.\n\n**4)** Make use of tables and plots that contributed to the improvement of your model.\n- Assume if increasing the epochs and decreasing the learning rate contributed in the improvement of your model.\n- You will first show these improvements using plots of val_iou_scores vs epochs as well as val_iou_scores vs learning rate.0\n- Then make use of tables to show iou scores for different learning rates.\n- For example, table 1 for lr_1 to show iou values for epochs 30 t0 50, table 2 to show iou values from epochs 30 to 50, and so on.\n- It is therefore advised to work on one improvement, optimize it, plot it, document it, then proceed to the next improvement - till you get a satisfactory IOU score.\n\n**5)** Final improvement summary table.\n- Prepare a table with columns (changes, improvments description, increase in iou from, increase in iou to)\n- List out all the changes you made to improve your final model performance.","metadata":{"id":"_qWKqzF4415S"}},{"cell_type":"markdown","source":"## Coding for this project","metadata":{"id":"FLuwoPcxn93E"}},{"cell_type":"code","source":"!pip install segmentation_models","metadata":{"id":"HRJUKjN1QXgS","execution":{"iopub.status.busy":"2023-01-27T13:41:40.976398Z","iopub.execute_input":"2023-01-27T13:41:40.977251Z","iopub.status.idle":"2023-01-27T13:41:54.079057Z","shell.execute_reply.started":"2023-01-27T13:41:40.977214Z","shell.execute_reply":"2023-01-27T13:41:54.077908Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting segmentation_models\n  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\nCollecting image-classifiers==1.0.0\n  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\nCollecting efficientnet==1.0.0\n  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.0.0->segmentation_models) (0.19.3)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.7.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.21.6)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2021.11.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (23.0)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.7.3)\nRequirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.5)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.0)\nRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.19.3)\nRequirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (9.1.1)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.2->scikit-image->efficientnet==1.0.0->segmentation_models) (5.1.1)\nInstalling collected packages: keras-applications, image-classifiers, efficientnet, segmentation_models\nSuccessfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation_models-1.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# import the necessary Library\n\nimport tensorflow as tf\nimport segmentation_models as sm\nimport glob\nimport cv2\nimport os\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport keras \nfrom sklearn.model_selection import train_test_split","metadata":{"id":"bGIcq3_DQXgT","execution":{"iopub.status.busy":"2023-01-27T13:41:54.081866Z","iopub.execute_input":"2023-01-27T13:41:54.083285Z","iopub.status.idle":"2023-01-27T13:42:00.461600Z","shell.execute_reply.started":"2023-01-27T13:41:54.083250Z","shell.execute_reply":"2023-01-27T13:42:00.460570Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Segmentation Models: using `keras` framework.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"* Provide environment variable SM_FRAMEWORK=keras / SM_FRAMEWORK=tf.keras before import segmentation_models\n* Change framework sm.set_framework('keras') / sm.set_framework('tf.keras')","metadata":{"id":"TIJMgWvKm8y7"}},{"cell_type":"code","source":"# Setting framework environment\nos.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\nsm.set_framework('tf.keras')\nkeras.backend.set_image_data_format('channels_last')","metadata":{"id":"x2HKIVofm8y7","execution":{"iopub.status.busy":"2023-01-27T13:42:00.463014Z","iopub.execute_input":"2023-01-27T13:42:00.464031Z","iopub.status.idle":"2023-01-27T13:42:00.864169Z","shell.execute_reply.started":"2023-01-27T13:42:00.463990Z","shell.execute_reply":"2023-01-27T13:42:00.863003Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing Pipeline","metadata":{"id":"OdS9NTtwQXgV"}},{"cell_type":"code","source":"H = 256 # height of image\nW = 256 # width of image\n\n'''This function is used to return the list of path for images and masks in\nsorted order from the given directory respectively.'''\n# function to return list of image paths and mask paths \ndef process_data(IMG_DIR, MASK_DIR):\n    images = [os.path.join(IMG_DIR, x) for x in sorted(os.listdir(IMG_DIR))]\n    masks = [os.path.join(MASK_DIR, x) for x in sorted(os.listdir(MASK_DIR))]\n\n    return images, masks\n\n'''This function is used to return splitted list of images and corresponding \nmask paths in train and test by providing test size.'''\n# function to load data and train test split\ndef load_data(IMG_DIR, MASK_DIR):\n    X, y = process_data(IMG_DIR, MASK_DIR)\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42)\n    \n    return X_train, X_test, y_train, y_test\n\n'''This function is used to read images. It takes image path as input. \nAfter reading image it is resized by width and height provide above(256 x 256). \nNext normalization is done by dividing each values with 255. And the result is returned.'''\n# function to read image\ndef read_image(x):\n    x = cv2.imread(x, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (W, H))\n    x = x / 255.0\n    x = x.astype(np.float32)\n    return x\n\n'''This function is used to read masks.'''\n# function to read mask\ndef read_mask(x):\n    x = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x, (W, H))\n    x = x.astype(np.int32)\n    return x\n\n'''This function is used to generate tensorflow data pipeline. \nThe tensorflow data pipeline is mapped to function ‘preprocess’ .'''\n# function for tensorflow dataset pipeline\ndef tf_dataset(x, y, batch=8):\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n    dataset = dataset.shuffle(buffer_size=5000)\n    dataset = dataset.map(preprocess)\n    dataset = dataset.batch(batch)\n    dataset = dataset.repeat()\n    dataset = dataset.prefetch(2)\n    return dataset\n\n'''This function takes image and mask path. \nIt reads the image and mask as provided by paths. \nMask is one hot encoded for multi class segmentation (here 4 class).'''\n# function to read image and mask amd create one hot encoding for mask\ndef preprocess(x, y):\n    def f(x, y):\n        x = x.decode()\n        y = y.decode()\n\n        image = read_image(x)\n        mask = read_mask(y)\n\n        return image, mask\n\n    image, mask = tf.numpy_function(f, [x, y], [tf.float32, tf.int32])\n    mask = tf.one_hot(mask, 4, dtype=tf.int32)\n    image.set_shape([H, W, 3])\n    mask.set_shape([H, W, 4])\n\n    return image, mask","metadata":{"id":"EQGsLbOVQXgW","execution":{"iopub.status.busy":"2023-01-27T13:42:00.866691Z","iopub.execute_input":"2023-01-27T13:42:00.867379Z","iopub.status.idle":"2023-01-27T13:42:00.886787Z","shell.execute_reply.started":"2023-01-27T13:42:00.867333Z","shell.execute_reply":"2023-01-27T13:42:00.885806Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Load the dataset","metadata":{"id":"ufOlyg7MQXgY"}},{"cell_type":"code","source":"'''RENDER_IMAGE_DIR_PATH: ‘Path of image directory’\nGROUND_MASK_DIR_PATH: ‘Path of mask directory’\n\nHere load_data function is called. This will load the dataset paths and \nsplit it into X_train, X_test, y_train, y_test '''\n\nRENDER_IMAGE_DIR_PATH = '../input/artificial-lunar-rocky-landscape-dataset/images/render'\nGROUND_MASK_DIR_PATH = '../input/artificial-lunar-rocky-landscape-dataset/images/ground'\n\nX_train, X_test, y_train, y_test = load_data(RENDER_IMAGE_DIR_PATH, GROUND_MASK_DIR_PATH)\nprint(f\"Dataset:\\n Train: {len(X_train)} \\n Test: {len(X_test)}\")","metadata":{"id":"vHWstFNTQXgY","execution":{"iopub.status.busy":"2023-01-27T13:42:00.893582Z","iopub.execute_input":"2023-01-27T13:42:00.898374Z","iopub.status.idle":"2023-01-27T13:42:01.264224Z","shell.execute_reply.started":"2023-01-27T13:42:00.898327Z","shell.execute_reply":"2023-01-27T13:42:01.263133Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Dataset:\n Train: 7812 \n Test: 1954\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Generate tensorflow data pipeline","metadata":{"id":"WfSTVsjCQXgZ"}},{"cell_type":"code","source":"batch_size = 8\n\n'''Here the tf_dataset function is called will generate the tensorflow data pipeline.'''\n# calling tf_dataset\ntrain_dataset = tf_dataset(X_train, y_train, batch=batch_size)\nvalid_dataset = tf_dataset(X_test, y_test, batch=batch_size)","metadata":{"id":"4xsJKtW0QXgZ","execution":{"iopub.status.busy":"2023-01-27T13:42:01.265613Z","iopub.execute_input":"2023-01-27T13:42:01.265975Z","iopub.status.idle":"2023-01-27T13:42:05.218588Z","shell.execute_reply.started":"2023-01-27T13:42:01.265937Z","shell.execute_reply":"2023-01-27T13:42:05.217611Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"2023-01-27 13:42:01.408252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 13:42:01.409249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 13:42:01.531825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 13:42:01.532766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 13:42:01.533668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 13:42:01.534487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 13:42:01.538597: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-01-27 13:42:01.798195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 13:42:01.799083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 13:42:01.799826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 13:42:01.800530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 13:42:01.801220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 13:42:01.801901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 13:42:04.686622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 13:42:04.687656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 13:42:04.688429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 13:42:04.689252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 13:42:04.689977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 13:42:04.690701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2023-01-27 13:42:04.693674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-27 13:42:04.694403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Creating U-net Architecture","metadata":{"id":"1MqxtDTmQXga"}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate\nfrom tensorflow.keras.models import Model\n\n'''conv_block it is used to create one block with two convolution layer \nfollowed by BatchNormalization and activation function relu. \nIf the pooling is required then Maxpool2D is applied and return it else not.'''\n# function to create convolution block\ndef conv_block(inputs, filters, pool=True):\n    x = Conv2D(filters, 3, padding=\"same\")(inputs)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    x = Conv2D(filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    if pool == True:\n        p = MaxPool2D((2, 2))(x)\n        return x, p\n    else:\n        return x\n\n'''build_unet it is used to create the U-net architecture.'''\n# function to build U-net\ndef build_unet(shape, num_classes):\n    inputs = Input(shape)\n\n    \"\"\" Encoder \"\"\"\n    x1, p1 = conv_block(inputs, 16, pool=True)\n    x2, p2 = conv_block(p1, 32, pool=True)\n    x3, p3 = conv_block(p2, 48, pool=True)\n    x4, p4 = conv_block(p3, 64, pool=True)\n\n    \"\"\" Bridge \"\"\"\n    b1 = conv_block(p4, 128, pool=False)\n\n    \"\"\" Decoder \"\"\"\n    u1 = UpSampling2D((2, 2), interpolation=\"bilinear\")(b1)\n    c1 = Concatenate()([u1, x4])\n    x5 = conv_block(c1, 64, pool=False)\n\n    u2 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x5)\n    c2 = Concatenate()([u2, x3])\n    x6 = conv_block(c2, 48, pool=False)\n\n    u3 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x6)\n    c3 = Concatenate()([u3, x2])\n    x7 = conv_block(c3, 32, pool=False)\n\n    u4 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x7)\n    c4 = Concatenate()([u4, x1])\n    x8 = conv_block(c4, 16, pool=False)\n\n    \"\"\" Output layer \"\"\"\n    output = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(x8)\n\n    return Model(inputs, output)","metadata":{"id":"tYCyf8smQXga","execution":{"iopub.status.busy":"2023-01-27T13:42:05.220233Z","iopub.execute_input":"2023-01-27T13:42:05.220593Z","iopub.status.idle":"2023-01-27T13:42:05.236384Z","shell.execute_reply.started":"2023-01-27T13:42:05.220555Z","shell.execute_reply":"2023-01-27T13:42:05.235413Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# calling build_unet function\nmodel = build_unet((256, 256, 3), 4)\n\n#printing model summary\n# model.summary()","metadata":{"id":"65hPnreJQXgb","execution":{"iopub.status.busy":"2023-01-27T14:02:12.335247Z","iopub.execute_input":"2023-01-27T14:02:12.335621Z","iopub.status.idle":"2023-01-27T14:02:12.664713Z","shell.execute_reply.started":"2023-01-27T14:02:12.335590Z","shell.execute_reply":"2023-01-27T14:02:12.663755Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Load model and compile","metadata":{"id":"bMgeqmX2QXgc"}},{"cell_type":"code","source":"# importing libraries\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\nfrom segmentation_models.metrics import iou_score\nimport datetime, os\n\n\"\"\" Defining Hyperparameters \"\"\"\nimg_shape = (256, 256, 3)\nnum_classes = 4\nlr = 1e-4\nbatch_size = 16\nepochs = 5\n\n\"\"\" Model building and compiling \"\"\"\nmodel = build_unet(img_shape, num_classes)\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=tf.keras.optimizers.Adam(lr), \n              metrics=[iou_score])\n\n\ntrain_steps = len(X_train)//batch_size\nvalid_steps = len(X_test)//batch_size","metadata":{"id":"z91qV2ZwQXgc","execution":{"iopub.status.busy":"2023-01-27T13:42:05.643093Z","iopub.execute_input":"2023-01-27T13:42:05.644324Z","iopub.status.idle":"2023-01-27T13:42:05.986574Z","shell.execute_reply.started":"2023-01-27T13:42:05.644284Z","shell.execute_reply":"2023-01-27T13:42:05.985589Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Train model","metadata":{"id":"SBhRPBKPQXgc"}},{"cell_type":"code","source":"'''model.fit is used to train the model'''\nmodel_history = model.fit(train_dataset,\n        steps_per_epoch=train_steps,\n        validation_data=valid_dataset,\n        validation_steps=valid_steps,\n        epochs=epochs,\n    )","metadata":{"id":"4lJgBNVwQXgd","execution":{"iopub.status.busy":"2023-01-27T13:42:05.989701Z","iopub.execute_input":"2023-01-27T13:42:05.990098Z","iopub.status.idle":"2023-01-27T13:51:34.753903Z","shell.execute_reply.started":"2023-01-27T13:42:05.990044Z","shell.execute_reply":"2023-01-27T13:51:34.753005Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"2023-01-27 13:42:06.024871: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"2023-01-27 13:42:09.860773: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"488/488 [==============================] - 163s 309ms/step - loss: 0.3834 - iou_score: 0.1429 - val_loss: 0.2605 - val_iou_score: 0.1608\nEpoch 2/5\n488/488 [==============================] - 144s 296ms/step - loss: 0.2127 - iou_score: 0.1719 - val_loss: 0.1928 - val_iou_score: 0.1764\nEpoch 3/5\n488/488 [==============================] - 90s 181ms/step - loss: 0.1493 - iou_score: 0.1855 - val_loss: 0.1224 - val_iou_score: 0.1916\nEpoch 4/5\n488/488 [==============================] - 86s 177ms/step - loss: 0.1096 - iou_score: 0.1934 - val_loss: 0.0937 - val_iou_score: 0.1956\nEpoch 5/5\n488/488 [==============================] - 86s 176ms/step - loss: 0.0834 - iou_score: 0.1983 - val_loss: 0.0601 - val_iou_score: 0.1877\n","output_type":"stream"}]},{"cell_type":"code","source":"# importing packages to visualize\nimport seaborn\nfrom matplotlib import pyplot","metadata":{"execution":{"iopub.status.busy":"2023-01-27T14:03:24.614173Z","iopub.execute_input":"2023-01-27T14:03:24.615236Z","iopub.status.idle":"2023-01-27T14:03:24.620867Z","shell.execute_reply.started":"2023-01-27T14:03:24.615195Z","shell.execute_reply":"2023-01-27T14:03:24.619688Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Try 1: Running with no changes","metadata":{"id":"I1OFxBbnxC_I"}},{"cell_type":"code","source":"model_history.","metadata":{"id":"X8f68O0lxXuP","execution":{"iopub.status.busy":"2023-01-27T14:04:43.699236Z","iopub.execute_input":"2023-01-27T14:04:43.699611Z","iopub.status.idle":"2023-01-27T14:04:43.721943Z","shell.execute_reply.started":"2023-01-27T14:04:43.699580Z","shell.execute_reply":"2023-01-27T14:04:43.720761Z"},"trusted":true},"execution_count":18,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3794032528.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'summary'"],"ename":"AttributeError","evalue":"'History' object has no attribute 'summary'","output_type":"error"}]},{"cell_type":"markdown","source":"---\n# <center> THE END","metadata":{"id":"NhX2Q9I6n93K"}}]}